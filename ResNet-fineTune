{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ResNet-fineTune","provenance":[{"file_id":"1weYZUfj5qbo9yIEUWKc23qYX9Vjf6kpj","timestamp":1570425489884}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"WZn3xCRTTs8P","colab_type":"code","outputId":"8c5493cf-d86f-4e55-d533-890512c013b3","executionInfo":{"status":"ok","timestamp":1570523051122,"user_tz":-480,"elapsed":18484,"user":{"displayName":"LIM CAI XIAN LUCINDA","photoUrl":"","userId":"12327338794304454977"}},"colab":{"base_uri":"https://localhost:8080/","height":120}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive/')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"m-SA6LhHrcnm","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":33},"outputId":"5093fcf3-2b31-4864-d296-e0e2344eeaa8","executionInfo":{"status":"ok","timestamp":1570523078795,"user_tz":-480,"elapsed":46154,"user":{"displayName":"LIM CAI XIAN LUCINDA","photoUrl":"","userId":"12327338794304454977"}}},"source":["!unzip -q '/content/gdrive/My Drive/Colab Notebooks/vip2/NWPUvip.zip'\n"],"execution_count":3,"outputs":[{"output_type":"stream","text":["A\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"b4a_aFd03UVl","colab_type":"code","outputId":"67c64085-c7d4-4c89-e2cc-b1e580e77f92","executionInfo":{"status":"ok","timestamp":1570523080571,"user_tz":-480,"elapsed":47293,"user":{"displayName":"LIM CAI XIAN LUCINDA","photoUrl":"","userId":"12327338794304454977"}},"colab":{"base_uri":"https://localhost:8080/","height":33}},"source":["from keras.applications.resnet50 import ResNet50\n","from keras import models\n","from keras import layers\n","from keras import optimizers\n","from keras.preprocessing.image import ImageDataGenerator, load_img"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"Ls5WGgJNrer9","colab_type":"code","colab":{}},"source":["train_dir = '/content/NWPU-RESISC12/train'\n","validation_dir = '/content/NWPU-RESISC12/test'\n","image_size = 224\n","nTrain = 6600\n","nVal = 1800"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0kxqKYE9fl22","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"X-L80zu2rj7i","colab_type":"code","outputId":"6a09ccb6-a05b-42dc-fe18-21b6aa956508","executionInfo":{"status":"ok","timestamp":1570523095494,"user_tz":-480,"elapsed":46443,"user":{"displayName":"LIM CAI XIAN LUCINDA","photoUrl":"","userId":"12327338794304454977"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["#Load the VGG model\n","res_conv = ResNet50(weights='imagenet', include_top=False, input_shape=(image_size, image_size, 3))\n","\n","# Freeze all layers except the last 4 layers\n","for layer in res_conv.layers:\n","    layer.trainable = False\n","\n","# Check the trainable status of the individual layers\n","for layer in res_conv.layers:\n","    print(layer,'\\t', layer.trainable)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4479: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n","  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"],"name":"stderr"},{"output_type":"stream","text":["Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n","94658560/94653016 [==============================] - 2s 0us/step\n","<keras.engine.input_layer.InputLayer object at 0x7faccc551dd8> \t False\n","<keras.layers.convolutional.ZeroPadding2D object at 0x7faccc551fd0> \t False\n","<keras.layers.convolutional.Conv2D object at 0x7faccc4e2390> \t False\n","<keras.layers.normalization.BatchNormalization object at 0x7faccc4e2400> \t False\n","<keras.layers.core.Activation object at 0x7faccc4e2f28> \t False\n","<keras.layers.convolutional.ZeroPadding2D object at 0x7faccc4e2dd8> \t False\n","<keras.layers.pooling.MaxPooling2D object at 0x7faccc4e2f60> \t False\n","<keras.layers.convolutional.Conv2D object at 0x7faccbcbcf60> \t False\n","<keras.layers.normalization.BatchNormalization object at 0x7fac807476a0> \t False\n","<keras.layers.core.Activation object at 0x7fac8076f358> \t False\n","<keras.layers.convolutional.Conv2D object at 0x7fac80747e10> \t False\n","<keras.layers.normalization.BatchNormalization object at 0x7fac80707860> \t False\n","<keras.layers.core.Activation object at 0x7fac80744f28> \t False\n","<keras.layers.convolutional.Conv2D object at 0x7fac806275c0> \t False\n","<keras.layers.convolutional.Conv2D object at 0x7fac805c5550> \t False\n","<keras.layers.normalization.BatchNormalization object at 0x7fac80607d30> \t False\n","<keras.layers.normalization.BatchNormalization object at 0x7fac80533e48> \t False\n","<keras.layers.merge.Add object at 0x7fac804ee828> \t False\n","<keras.layers.core.Activation object at 0x7fac80481fd0> \t False\n","<keras.layers.convolutional.Conv2D object at 0x7fac804616a0> \t False\n","<keras.layers.normalization.BatchNormalization object at 0x7fac8041d198> \t False\n","<keras.layers.core.Activation object at 0x7fac803ef898> \t False\n","<keras.layers.convolutional.Conv2D object at 0x7fac80305390> \t False\n","<keras.layers.normalization.BatchNormalization object at 0x7fac8034cc18> \t False\n","<keras.layers.core.Activation object at 0x7fac80335908> \t False\n","<keras.layers.convolutional.Conv2D object at 0x7fac80271e80> \t False\n","<keras.layers.normalization.BatchNormalization object at 0x7fac8024cfd0> \t False\n","<keras.layers.merge.Add object at 0x7fac8020c9e8> \t False\n","<keras.layers.core.Activation object at 0x7fac80202d68> \t False\n","<keras.layers.convolutional.Conv2D object at 0x7fac80202b70> \t False\n","<keras.layers.normalization.BatchNormalization object at 0x7fac8016af28> \t False\n","<keras.layers.core.Activation object at 0x7fac800e9278> \t False\n","<keras.layers.convolutional.Conv2D object at 0x7fac80051630> \t False\n","<keras.layers.normalization.BatchNormalization object at 0x7fac800aedd8> \t False\n","<keras.layers.core.Activation object at 0x7fac8006c588> \t False\n","<keras.layers.convolutional.Conv2D object at 0x7fac7ffb3d30> \t False\n","<keras.layers.normalization.BatchNormalization object at 0x7fac7ff947f0> \t False\n","<keras.layers.merge.Add object at 0x7fac7ff54be0> \t False\n","<keras.layers.core.Activation object at 0x7fac7fef0780> \t False\n","<keras.layers.convolutional.Conv2D object at 0x7fac7fef08d0> \t False\n","<keras.layers.normalization.BatchNormalization object at 0x7fac7fe5e2e8> \t False\n","<keras.layers.core.Activation object at 0x7fac7fe35208> \t False\n","<keras.layers.convolutional.Conv2D object at 0x7fac7fda1e80> \t False\n","<keras.layers.normalization.BatchNormalization object at 0x7fac7fe02f28> \t False\n","<keras.layers.core.Activation object at 0x7fac7fdc1ba8> \t False\n","<keras.layers.convolutional.Conv2D object at 0x7fac7fcd8400> \t False\n","<keras.layers.convolutional.Conv2D object at 0x7fac7fc4b2b0> \t False\n","<keras.layers.normalization.BatchNormalization object at 0x7fac7fca81d0> \t False\n","<keras.layers.normalization.BatchNormalization object at 0x7fac7fbb05f8> \t False\n","<keras.layers.merge.Add object at 0x7fac7fb6c4e0> \t False\n","<keras.layers.core.Activation object at 0x7fac7fb29f60> \t False\n","<keras.layers.convolutional.Conv2D object at 0x7fac7fb292e8> \t False\n","<keras.layers.normalization.BatchNormalization object at 0x7fac7fa98a20> \t False\n","<keras.layers.core.Activation object at 0x7fac7fa6a9e8> \t False\n","<keras.layers.convolutional.Conv2D object at 0x7fac7fa013c8> \t False\n","<keras.layers.normalization.BatchNormalization object at 0x7fac7f9c5fd0> \t False\n","<keras.layers.core.Activation object at 0x7fac7f9b3940> \t False\n","<keras.layers.convolutional.Conv2D object at 0x7fac7f915e48> \t False\n","<keras.layers.normalization.BatchNormalization object at 0x7fac7f8c9550> \t False\n","<keras.layers.merge.Add object at 0x7fac7f8869e8> \t False\n","<keras.layers.core.Activation object at 0x7fac7f873e80> \t False\n","<keras.layers.convolutional.Conv2D object at 0x7fac7f873c88> \t False\n","<keras.layers.normalization.BatchNormalization object at 0x7fac7f7df828> \t False\n","<keras.layers.core.Activation object at 0x7fac7f7553c8> \t False\n","<keras.layers.convolutional.Conv2D object at 0x7fac7f743828> \t False\n","<keras.layers.normalization.BatchNormalization object at 0x7fac7f724ef0> \t False\n","<keras.layers.core.Activation object at 0x7fac7f6e2198> \t False\n","<keras.layers.convolutional.Conv2D object at 0x7fac7f62be48> \t False\n","<keras.layers.normalization.BatchNormalization object at 0x7fac7f60f908> \t False\n","<keras.layers.merge.Add object at 0x7fac7f5cfcf8> \t False\n","<keras.layers.core.Activation object at 0x7fac7f562898> \t False\n","<keras.layers.convolutional.Conv2D object at 0x7fac7f5629e8> \t False\n","<keras.layers.normalization.BatchNormalization object at 0x7fac7f4d4470> \t False\n","<keras.layers.core.Activation object at 0x7fac7f4a2320> \t False\n","<keras.layers.convolutional.Conv2D object at 0x7fac7f412f98> \t False\n","<keras.layers.normalization.BatchNormalization object at 0x7fac7f47b748> \t False\n","<keras.layers.core.Activation object at 0x7fac7f436b38> \t False\n","<keras.layers.convolutional.Conv2D object at 0x7fac7f31f2e8> \t False\n","<keras.layers.normalization.BatchNormalization object at 0x7fac7f366ef0> \t False\n","<keras.layers.merge.Add object at 0x7fac7f2cf860> \t False\n","<keras.layers.core.Activation object at 0x7fac7f24dcf8> \t False\n","<keras.layers.convolutional.Conv2D object at 0x7fac7f268518> \t False\n","<keras.layers.normalization.BatchNormalization object at 0x7fac7f2299e8> \t False\n","<keras.layers.core.Activation object at 0x7fac7f1f5780> \t False\n","<keras.layers.convolutional.Conv2D object at 0x7fac7f1b9390> \t False\n","<keras.layers.normalization.BatchNormalization object at 0x7fac7f1579b0> \t False\n","<keras.layers.core.Activation object at 0x7fac7f10def0> \t False\n","<keras.layers.convolutional.Conv2D object at 0x7fac7f075710> \t False\n","<keras.layers.convolutional.Conv2D object at 0x7fac7f0126a0> \t False\n","<keras.layers.normalization.BatchNormalization object at 0x7fac7f054dd8> \t False\n","<keras.layers.normalization.BatchNormalization object at 0x7fac7ef7bcf8> \t False\n","<keras.layers.merge.Add object at 0x7fac7eef3cc0> \t False\n","<keras.layers.core.Activation object at 0x7fac7ee8deb8> \t False\n","<keras.layers.convolutional.Conv2D object at 0x7fac7ee8db70> \t False\n","<keras.layers.normalization.BatchNormalization object at 0x7fac7ee05898> \t False\n","<keras.layers.core.Activation object at 0x7fac7edd1ef0> \t False\n","<keras.layers.convolutional.Conv2D object at 0x7fac7ed655f8> \t False\n","<keras.layers.normalization.BatchNormalization object at 0x7fac7ed47d68> \t False\n","<keras.layers.core.Activation object at 0x7fac7ed055c0> \t False\n","<keras.layers.convolutional.Conv2D object at 0x7fac7ec50f28> \t False\n","<keras.layers.normalization.BatchNormalization object at 0x7fac7ecaf6d8> \t False\n","<keras.layers.merge.Add object at 0x7fac7ec6cc50> \t False\n","<keras.layers.core.Activation object at 0x7fac7eb864e0> \t False\n","<keras.layers.convolutional.Conv2D object at 0x7fac7eb86c50> \t False\n","<keras.layers.normalization.BatchNormalization object at 0x7fac7eb76208> \t False\n","<keras.layers.core.Activation object at 0x7fac7eb41710> \t False\n","<keras.layers.convolutional.Conv2D object at 0x7fac7ea88320> \t False\n","<keras.layers.normalization.BatchNormalization object at 0x7fac7eaa27f0> \t False\n","<keras.layers.core.Activation object at 0x7fac7ea5ef98> \t False\n","<keras.layers.convolutional.Conv2D object at 0x7fac7e9c16d8> \t False\n","<keras.layers.normalization.BatchNormalization object at 0x7fac7e9a0e48> \t False\n","<keras.layers.merge.Add object at 0x7fac7e95d588> \t False\n","<keras.layers.core.Activation object at 0x7fac7e8d7940> \t False\n","<keras.layers.convolutional.Conv2D object at 0x7fac7e8d7b38> \t False\n","<keras.layers.normalization.BatchNormalization object at 0x7fac7e84a1d0> \t False\n","<keras.layers.core.Activation object at 0x7fac7e83f1d0> \t False\n","<keras.layers.convolutional.Conv2D object at 0x7fac7e7f4d30> \t False\n","<keras.layers.normalization.BatchNormalization object at 0x7fac7e78cf98> \t False\n","<keras.layers.core.Activation object at 0x7fac7e749b38> \t False\n","<keras.layers.convolutional.Conv2D object at 0x7fac7e6df400> \t False\n","<keras.layers.normalization.BatchNormalization object at 0x7fac7e651710> \t False\n","<keras.layers.merge.Add object at 0x7fac7e662710> \t False\n","<keras.layers.core.Activation object at 0x7fac7e5c5c88> \t False\n","<keras.layers.convolutional.Conv2D object at 0x7fac7e5c5cc0> \t False\n","<keras.layers.normalization.BatchNormalization object at 0x7fac7e5b78d0> \t False\n","<keras.layers.core.Activation object at 0x7fac7e506f28> \t False\n","<keras.layers.convolutional.Conv2D object at 0x7fac7e49d5f8> \t False\n","<keras.layers.normalization.BatchNormalization object at 0x7fac7e4fdd68> \t False\n","<keras.layers.core.Activation object at 0x7fac7e4ba5c0> \t False\n","<keras.layers.convolutional.Conv2D object at 0x7fac7e404f28> \t False\n","<keras.layers.normalization.BatchNormalization object at 0x7fac7e3e36d8> \t False\n","<keras.layers.merge.Add object at 0x7fac7e3a3c50> \t False\n","<keras.layers.core.Activation object at 0x7fac7e33b4e0> \t False\n","<keras.layers.convolutional.Conv2D object at 0x7fac7e33bc50> \t False\n","<keras.layers.normalization.BatchNormalization object at 0x7fac7e2ab208> \t False\n","<keras.layers.core.Activation object at 0x7fac7e278710> \t False\n","<keras.layers.convolutional.Conv2D object at 0x7fac7e23b2e8> \t False\n","<keras.layers.normalization.BatchNormalization object at 0x7fac7e1d77f0> \t False\n","<keras.layers.core.Activation object at 0x7fac7e192550> \t False\n","<keras.layers.convolutional.Conv2D object at 0x7fac7e0f56d8> \t False\n","<keras.layers.normalization.BatchNormalization object at 0x7fac7e0d7e48> \t False\n","<keras.layers.merge.Add object at 0x7fac7e093588> \t False\n","<keras.layers.core.Activation object at 0x7fac7e00d940> \t False\n","<keras.layers.convolutional.Conv2D object at 0x7fac7e00db38> \t False\n","<keras.layers.normalization.BatchNormalization object at 0x7fac7dffd1d0> \t False\n","<keras.layers.core.Activation object at 0x7fac7df741d0> \t False\n","<keras.layers.convolutional.Conv2D object at 0x7fac7df2cd30> \t False\n","<keras.layers.normalization.BatchNormalization object at 0x7fac7df43f98> \t False\n","<keras.layers.core.Activation object at 0x7fac7df02b70> \t False\n","<keras.layers.convolutional.Conv2D object at 0x7fac7de7be10> \t False\n","<keras.layers.convolutional.Conv2D object at 0x7fac7ddeab00> \t False\n","<keras.layers.normalization.BatchNormalization object at 0x7fac7ddbdfd0> \t False\n","<keras.layers.normalization.BatchNormalization object at 0x7fac7dceedd8> \t False\n","<keras.layers.merge.Add object at 0x7fac7dcaa7b8> \t False\n","<keras.layers.core.Activation object at 0x7fac7dc6b898> \t False\n","<keras.layers.convolutional.Conv2D object at 0x7fac7dc35d30> \t False\n","<keras.layers.normalization.BatchNormalization object at 0x7fac7db85e48> \t False\n","<keras.layers.core.Activation object at 0x7fac7db46630> \t False\n","<keras.layers.convolutional.Conv2D object at 0x7fac7db0c278> \t False\n","<keras.layers.normalization.BatchNormalization object at 0x7fac7db23748> \t False\n","<keras.layers.core.Activation object at 0x7fac7dadfeb8> \t False\n","<keras.layers.convolutional.Conv2D object at 0x7fac7da43630> \t False\n","<keras.layers.normalization.BatchNormalization object at 0x7fac7da21da0> \t False\n","<keras.layers.merge.Add object at 0x7fac7d9f5b70> \t False\n","<keras.layers.core.Activation object at 0x7fac7d958eb8> \t False\n","<keras.layers.convolutional.Conv2D object at 0x7fac7d9588d0> \t False\n","<keras.layers.normalization.BatchNormalization object at 0x7fac7d8cb278> \t False\n","<keras.layers.core.Activation object at 0x7fac7d847128> \t False\n","<keras.layers.convolutional.Conv2D object at 0x7fac7d878c88> \t False\n","<keras.layers.normalization.BatchNormalization object at 0x7fac7d811ef0> \t False\n","<keras.layers.core.Activation object at 0x7fac7d7d2908> \t False\n","<keras.layers.convolutional.Conv2D object at 0x7fac7d763320> \t False\n","<keras.layers.normalization.BatchNormalization object at 0x7fac7d77e828> \t False\n","<keras.layers.merge.Add object at 0x7fac7d734f98> \t False\n","<keras.layers.core.Activation object at 0x7fac7d649c18> \t False\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Tk_EsJC6U7RM","colab_type":"code","outputId":"05bd9e0e-43e4-4df9-cf14-e4176a16e454","executionInfo":{"status":"ok","timestamp":1570523099468,"user_tz":-480,"elapsed":47285,"user":{"displayName":"LIM CAI XIAN LUCINDA","photoUrl":"","userId":"12327338794304454977"}},"colab":{"base_uri":"https://localhost:8080/","height":251}},"source":["\n","from keras.layers import GlobalAveragePooling2D\n","# Create the model\n","model = models.Sequential()\n","\n","# Add the vgg convolutional base model\n","model.add(res_conv)\n","\n","# Add new layers\n","model.add(GlobalAveragePooling2D())\n","\n","model.add(layers.Dense(12, activation='softmax'))\n","\n","\n","# Show a summary of the model. Check the number of trainable parameters\n","model.summary()"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","resnet50 (Model)             (None, 7, 7, 2048)        23587712  \n","_________________________________________________________________\n","global_average_pooling2d_1 ( (None, 2048)              0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 12)                24588     \n","=================================================================\n","Total params: 23,612,300\n","Trainable params: 24,588\n","Non-trainable params: 23,587,712\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"i9KvMfbHVaCh","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"t1ezr0mUVSax","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":50},"outputId":"7d40e987-4c8c-4291-cac4-7e7a67728d56","executionInfo":{"status":"ok","timestamp":1570523099709,"user_tz":-480,"elapsed":44597,"user":{"displayName":"LIM CAI XIAN LUCINDA","photoUrl":"","userId":"12327338794304454977"}}},"source":["# No Data augmentation \n","train_datagen = ImageDataGenerator(rescale=1./255,rotation_range=20,\n","                                   horizontal_flip=True, \n","                                   validation_split=0.2)\n","validation_datagen = ImageDataGenerator(rescale=1./255,rotation_range=20,\n","                                   horizontal_flip=True, \n","                                   validation_split=0.2)\n","\n","# Change the batchsize according to your system RAM\n","train_batchsize = 32\n","val_batchsize = 16\n","\n","# Data Generator for Training data\n","train_generator = train_datagen.flow_from_directory(\n","        train_dir,\n","        target_size=(image_size, image_size),\n","        batch_size=train_batchsize,\n","        class_mode='categorical'\n","        #shuffle=True\n","        )\n","\n","# Data Generator for Validation data\n","validation_generator = validation_datagen.flow_from_directory(\n","        validation_dir,\n","        target_size=(image_size, image_size),\n","        batch_size=val_batchsize,\n","        class_mode='categorical'\n","        #shuffle=False\n","        )\n"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Found 6600 images belonging to 12 classes.\n","Found 1800 images belonging to 12 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_DbKSTJsr_Xi","colab_type":"code","outputId":"f63f0faf-3fae-4f1d-98b6-b0684b2e369a","executionInfo":{"status":"ok","timestamp":1570525503955,"user_tz":-480,"elapsed":2443126,"user":{"displayName":"LIM CAI XIAN LUCINDA","photoUrl":"","userId":"12327338794304454977"}},"colab":{"base_uri":"https://localhost:8080/","height":789}},"source":["# Compile the model\n","model.compile(loss='categorical_crossentropy',\n","              # optimizer=optimizers.RMSprop(lr=1e-4),\n","              optimizer='adam',\n","              metrics=['acc'])\n","\n","# Train the Model\n","history = model.fit_generator(\n","      train_generator,\n","      steps_per_epoch=train_generator.samples/train_generator.batch_size ,\n","      epochs=20,\n","      validation_data=validation_generator,\n","      validation_steps=validation_generator.samples/validation_generator.batch_size,\n","      verbose=1)\n","\n","\n","\n","                                                                                                                                                                                                                                         "],"execution_count":9,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","Epoch 1/20\n","207/206 [==============================] - 129s 625ms/step - loss: 0.6470 - acc: 0.7992 - val_loss: 3.9211 - val_acc: 0.0822\n","Epoch 2/20\n","207/206 [==============================] - 120s 578ms/step - loss: 0.3097 - acc: 0.9004 - val_loss: 4.4697 - val_acc: 0.0828\n","Epoch 3/20\n","207/206 [==============================] - 121s 583ms/step - loss: 0.2435 - acc: 0.9177 - val_loss: 4.6316 - val_acc: 0.0833\n","Epoch 4/20\n","207/206 [==============================] - 120s 578ms/step - loss: 0.2109 - acc: 0.9272 - val_loss: 4.9824 - val_acc: 0.0833\n","Epoch 5/20\n","207/206 [==============================] - 120s 579ms/step - loss: 0.1865 - acc: 0.9375 - val_loss: 5.3837 - val_acc: 0.0833\n","Epoch 6/20\n","207/206 [==============================] - 120s 580ms/step - loss: 0.1670 - acc: 0.9484 - val_loss: 5.5269 - val_acc: 0.0833\n","Epoch 7/20\n","207/206 [==============================] - 119s 574ms/step - loss: 0.1412 - acc: 0.9526 - val_loss: 5.7387 - val_acc: 0.0833\n","Epoch 8/20\n","207/206 [==============================] - 119s 574ms/step - loss: 0.1389 - acc: 0.9528 - val_loss: 6.2085 - val_acc: 0.0861\n","Epoch 9/20\n","207/206 [==============================] - 120s 578ms/step - loss: 0.1280 - acc: 0.9580 - val_loss: 6.2516 - val_acc: 0.0833\n","Epoch 10/20\n","207/206 [==============================] - 119s 575ms/step - loss: 0.1244 - acc: 0.9586 - val_loss: 6.5559 - val_acc: 0.0833\n","Epoch 11/20\n","207/206 [==============================] - 120s 579ms/step - loss: 0.1130 - acc: 0.9639 - val_loss: 6.3574 - val_acc: 0.0789\n","Epoch 12/20\n","207/206 [==============================] - 119s 576ms/step - loss: 0.1072 - acc: 0.9642 - val_loss: 6.7540 - val_acc: 0.0833\n","Epoch 13/20\n","207/206 [==============================] - 120s 580ms/step - loss: 0.1059 - acc: 0.9626 - val_loss: 6.5604 - val_acc: 0.0833\n","Epoch 14/20\n","207/206 [==============================] - 119s 577ms/step - loss: 0.1021 - acc: 0.9660 - val_loss: 6.7896 - val_acc: 0.0833\n","Epoch 15/20\n","207/206 [==============================] - 120s 581ms/step - loss: 0.1126 - acc: 0.9586 - val_loss: 7.2888 - val_acc: 0.0817\n","Epoch 16/20\n","207/206 [==============================] - 119s 577ms/step - loss: 0.0875 - acc: 0.9722 - val_loss: 7.3894 - val_acc: 0.0806\n","Epoch 17/20\n","207/206 [==============================] - 119s 577ms/step - loss: 0.0992 - acc: 0.9657 - val_loss: 7.4590 - val_acc: 0.0833\n","Epoch 18/20\n","207/206 [==============================] - 120s 578ms/step - loss: 0.0854 - acc: 0.9746 - val_loss: 7.5528 - val_acc: 0.0828\n","Epoch 19/20\n","207/206 [==============================] - 120s 579ms/step - loss: 0.0844 - acc: 0.9700 - val_loss: 7.8312 - val_acc: 0.0833\n","Epoch 20/20\n","207/206 [==============================] - 120s 582ms/step - loss: 0.0707 - acc: 0.9755 - val_loss: 7.6900 - val_acc: 0.0811\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Z1cvMmdZb_ry","colab_type":"code","colab":{}},"source":["# Save the Model\n","model.save('/content/gdrive/My Drive/Colab Notebooks/vip2/ResNetFineTune.h5')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6rVdhTUJsRBG","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","# Plot the accuracy and loss curves\n","acc = history.history['acc']\n","val_acc = history.history['val_acc']\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","\n","epochs = range(len(acc))\n","\n","plt.plot(epochs, acc, 'b', label='Training acc')\n","plt.plot(epochs, val_acc, 'r', label='Validation acc')\n","plt.title('Training and validation accuracy')\n","plt.legend()\n","\n","plt.figure()\n","\n","plt.plot(epochs, loss, 'b', label='Training loss')\n","plt.plot(epochs, val_loss, 'r', label='Validation loss')\n","plt.title('Training and validation loss')\n","plt.legend()\n","\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"L7B8E_c8sUlG","colab_type":"code","colab":{}},"source":["import numpy as np\n","# Create a generator for prediction\n","validation_generator = validation_datagen.flow_from_directory(\n","        validation_dir,\n","        target_size=(image_size, image_size),\n","        batch_size=val_batchsize,\n","        class_mode='categorical',\n","        shuffle=False)\n","\n","# Get the filenames from the generator\n","fnames = validation_generator.filenames\n","\n","# Get the ground truth from generator\n","ground_truth = validation_generator.classes\n","\n","# Get the label to class mapping from the generator\n","label2index = validation_generator.class_indices\n","\n","# Getting the mapping from class index to class label\n","idx2label = dict((v,k) for k,v in label2index.items())\n","\n","# Get the predictions from the model using the generator\n","predictions = model.predict_generator(validation_generator, steps=validation_generator.samples/validation_generator.batch_size,verbose=1)\n","predicted_classes = np.argmax(predictions,axis=1)\n","\n","errors = np.where(predicted_classes != ground_truth)[0]\n","print(\"No of errors = {}/{}\".format(len(errors),validation_generator.samples))\n","\n","'''\n","# Show the errors\n","for i in range(len(errors)):\n","    pred_class = np.argmax(predictions[errors[i]])\n","    pred_label = idx2label[pred_class]\n","    \n","    title = 'Original label:{}, Prediction :{}, confidence : {:.3f}'.format(\n","        fnames[errors[i]].split('/')[0],\n","        pred_label,\n","        predictions[errors[i]][pred_class])\n","    \n","    original = load_img('{}/{}'.format(validation_dir,fnames[errors[i]]))\n","    plt.figure(figsize=[7,7])\n","    plt.axis('off')\n","    plt.title(title)\n","    plt.imshow(original)\n","    plt.show()\n","'''"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"E61pgPxz959H","colab_type":"code","colab":{}},"source":["print(predicted_classes)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"DAP3uEfnEmmW","colab":{}},"source":["from sklearn.metrics import confusion_matrix\n","confusion_matrix(ground_truth, predicted_classes, labels=None, sample_weight=None)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"daGu2t3dEo6I","colab_type":"code","colab":{}},"source":["from sklearn.metrics import precision_score,recall_score,f1_score,accuracy_score\n","precision_score(ground_truth, predicted_classes,average='macro')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vnQdjKuHITxS","colab_type":"code","colab":{}},"source":["recall_score(ground_truth, predicted_classes,average='macro')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0XR0g8tvIhuI","colab_type":"code","colab":{}},"source":["f1_score(ground_truth, predicted_classes,average='macro')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rgRoqsMMNOvl","colab_type":"code","colab":{}},"source":["accuracy_score(ground_truth, predicted_classes)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ct4-zuTPmQSa","colab_type":"code","colab":{}},"source":["model.save_weights('/content/gdrive/My Drive/Colab Notebooks/vip2/ResNetFineTune_weights.h5')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-8UtFPJRnTs4","colab_type":"code","colab":{}},"source":["res_conv2 = ResNet50(weights='imagenet', include_top=False, input_shape=(image_size, image_size, 3))\n","        \n","for layer in res_conv2.layers[:-16]:\n","  layer.trainable = False\n","\n","for layer in model.layers:\n","    if hasattr(layer, 'moving_mean') and hasattr(layer, 'moving_variance'):\n","        layer.trainable = True\n","        K.eval(K.update(layer.moving_mean, K.zeros_like(layer.moving_mean)))\n","        K.eval(K.update(layer.moving_variance, K.zeros_like(layer.moving_variance)))\n","    else:\n","        layer.trainable = False\n","\n","print(res_conv2.summary())\n","for layer in res_conv2.layers:\n","  print(layer,'\\t',layer.trainable)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iLqMQjRJHYM9","colab_type":"code","colab":{}},"source":["res_conv3 = ResNet50(weights='imagenet', include_top=True, input_shape=(image_size, image_size, 3))\n","res_conv3.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kpwsQI5vr--P","colab_type":"code","colab":{}},"source":["model.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-8shD8Jg2r2f","colab_type":"code","colab":{}},"source":["from keras.models import load_model\n","model = load_model('/content/gdrive/My Drive/Colab Notebooks/vip2/ResNetFineTune.h5')\n","model.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"d6UR8yFyt1Ca","colab_type":"code","colab":{}},"source":["from keras.layers import GlobalAveragePooling2D\n","new_model2 = models.Sequential()\n","new_model2.add(res_conv2)\n","new_model2.add(GlobalAveragePooling2D())\n","new_model2.add(layers.Dense(12, activation='softmax'))\n","new_model2.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"szR5uBLsv8Wf","colab_type":"code","colab":{}},"source":["new_model2.layers[-1].set_weights(model.layers[-1].get_weights())\n","new_model2.layers[-2].set_weights(model.layers[-2].get_weights())\n","new_model2.layers[-3].set_weights(model.layers[-3].get_weights())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZLbQ7UBDw6LT","colab_type":"code","colab":{}},"source":["new_model2.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"c2IQaJ9dxnQr","colab_type":"code","colab":{}},"source":["model.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Hb-lRGmE1g1s","colab_type":"code","colab":{}},"source":["# Compile the model\n","new_model2.compile(loss='categorical_crossentropy',\n","              optimizer=optimizers.RMSprop(lr=1e-4),\n","              metrics=['acc'])\n","\n","# Train the Model\n","history = new_model2.fit_generator(\n","      train_generator,\n","      steps_per_epoch=train_generator.samples/train_generator.batch_size ,\n","      epochs=20,\n","      validation_data=validation_generator,\n","      validation_steps=validation_generator.samples/validation_generator.batch_size,\n","      verbose=1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ir1UEYBQ8T9Y","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}